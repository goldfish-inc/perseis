#!/usr/bin/env python3
"""
Enhanced Clean and process MSC gear type data for database import with UUID support.
This script:
1. Cleans the gear_types_msc.csv file (UUID-ready, no manual ID generation)
2. Processes gear_types_msc_fao_relationship.csv to split 1:many relationships into 1:1
3. Prepares data for UUID-based foreign key lookups
4. Creates properly formatted CSV files for enhanced database import with source tracking
"""

import pandas as pd
import logging
import sys
import os

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def clean_msc_gear_types():
    """Clean the MSC gear types file - UUID ready, no manual ID generation."""
    try:
        # Read the MSC gear types file
        logger.info("Reading gearTypes_msc.csv...")
        msc_file = '/import/gearTypes_msc.csv'
        if not os.path.exists(msc_file):
            logger.error(f"File not found: {msc_file}")
            return False
            
        df_msc = pd.read_csv(msc_file, encoding='utf-8')
        logger.info(f"Original MSC gear types: {len(df_msc)} rows")
        
        # NO LONGER ADD MANUAL ID - database will generate UUID
        
        # Basic cleaning
        df_msc['msc_gear'] = df_msc['msc_gear'].astype(str).str.strip()
        
        # Remove duplicates and empty values
        df_msc = df_msc.dropna(subset=['msc_gear'])
        df_msc = df_msc[df_msc['msc_gear'] != '']
        df_msc = df_msc.drop_duplicates(subset=['msc_gear'])
        
        # Keep only essential column for SQL import (UUID will be generated by database)
        df_msc = df_msc[['msc_gear']]
        
        # Save cleaned file
        output_file = '/import/cleaned_gear_types_msc.csv'
        df_msc.to_csv(output_file, index=False, encoding='utf-8')
        logger.info(f"Cleaned MSC gear types saved: {len(df_msc)} rows -> {output_file}")
        logger.info(f"📋 Sample data: {df_msc.head(2).to_dict('records')}")
        logger.info("🔄 UUID generation will be handled during SQL import phase")
        
        return True
        
    except Exception as e:
        logger.error(f"Error cleaning MSC gear types: {str(e)}")
        return False

def process_msc_fao_relationship():
    """Process the MSC-FAO relationship file - prepare for UUID foreign key lookups."""
    try:
        # Read the relationship file
        logger.info("Reading gearTypes_msc_fao_relationship.csv...")
        rel_file = '/import/gearTypes_msc_fao_relationship.csv'
        if not os.path.exists(rel_file):
            logger.error(f"File not found: {rel_file}")
            return False
            
        df_rel = pd.read_csv(rel_file, encoding='utf-8')
        logger.info(f"Original relationship records: {len(df_rel)} rows")
        
        # Clean and prepare data
        df_rel['msc_gear'] = df_rel['msc_gear'].astype(str).str.strip()
        df_rel['fao_isscfg_alpha'] = df_rel['fao_isscfg_alpha'].astype(str).str.strip()
        
        # Remove rows with missing essential data
        df_rel = df_rel.dropna(subset=['msc_gear', 'fao_isscfg_alpha'])
        df_rel = df_rel[(df_rel['msc_gear'] != '') & (df_rel['fao_isscfg_alpha'] != '')]
        
        # Split the fao_isscfg_alpha values that contain multiple codes
        expanded_rows = []
        
        for _, row in df_rel.iterrows():
            msc_gear = row['msc_gear']
            fao_codes = row['fao_isscfg_alpha']
            
            # Split by '; ' delimiter
            if '; ' in fao_codes:
                codes = [code.strip() for code in fao_codes.split('; ')]
                for code in codes:
                    if code:  # Skip empty codes
                        expanded_rows.append({
                            'msc_gear': msc_gear,
                            'fao_isscfg_alpha': code
                        })
            else:
                # Single code
                expanded_rows.append({
                    'msc_gear': msc_gear,
                    'fao_isscfg_alpha': fao_codes
                })
        
        # Create new DataFrame from expanded rows
        df_expanded = pd.DataFrame(expanded_rows)
        
        # Remove duplicates (same msc_gear + fao_isscfg_alpha combination)
        df_expanded = df_expanded.drop_duplicates(subset=['msc_gear', 'fao_isscfg_alpha'])
        
        # Keep only essential columns for SQL import (UUID mapping will happen in SQL)
        df_expanded = df_expanded[['msc_gear', 'fao_isscfg_alpha']]
        
        # Save the processed file
        output_file = '/import/cleaned_gear_types_fao_msc_relationship.csv'
        df_expanded.to_csv(output_file, index=False, encoding='utf-8')
        
        logger.info(f"Processed relationship file:")
        logger.info(f"  Original records: {len(df_rel)}")
        logger.info(f"  Expanded to 1:1 relationships: {len(df_expanded)}")
        logger.info(f"  Unique MSC gears: {df_expanded['msc_gear'].nunique()}")
        logger.info(f"  Unique FAO codes: {df_expanded['fao_isscfg_alpha'].nunique()}")
        logger.info(f"  Saved to: {output_file}")
        logger.info("🔄 UUID foreign key mapping will be handled during SQL import phase")
        
        # Show some examples of the expansion
        logger.info("\nExamples of 1:many -> 1:1 expansion:")
        sample_msc = df_expanded['msc_gear'].value_counts().head(3)
        for msc_gear in sample_msc.index:
            fao_codes = df_expanded[df_expanded['msc_gear'] == msc_gear]['fao_isscfg_alpha'].tolist()
            logger.info(f"  '{msc_gear}' -> {fao_codes}")
        
        return True
        
    except Exception as e:
        logger.error(f"Error processing MSC-FAO relationship: {str(e)}")
        return False

def show_msc_source_mapping_plan():
    """Show the planned source mapping for MSC gear data"""
    logger.info("\n📋 PLANNED MSC GEAR SOURCE MAPPING:")
    logger.info("=" * 50)
    logger.info("MSC Gear Table -> Original Source")
    logger.info("-" * 50)
    logger.info("gear_types_msc -> MSC Fisheries")
    logger.info("")
    logger.info("⚠️  This source must exist in original_sources.csv")
    logger.info("   with source_shortname = 'MSC Fisheries'")
    logger.info("")
    logger.info("🔄 UUID Mapping Strategy:")
    logger.info("   ✅ No more manual ID generation")
    logger.info("   ✅ Database generates all primary key UUIDs")
    logger.info("   ✅ Relationship table uses UUID foreign keys")
    logger.info("   ✅ msc_gear -> msc_gear_id UUID lookup")
    logger.info("   ✅ fao_isscfg_alpha -> fao_gear_id UUID lookup")
    logger.info("=" * 50)

def validate_cleaned_data():
    """Validate that cleaned files are ready for SQL import"""
    logger.info("\n🔍 Validating cleaned MSC gear data for SQL import...")
    
    validation_passed = True
    
    # Check MSC gear file
    try:
        msc_df = pd.read_csv("/import/cleaned_gear_types_msc.csv")
        required_msc_cols = ['msc_gear']
        
        missing_msc_cols = set(required_msc_cols) - set(msc_df.columns)
        if missing_msc_cols:
            logger.error(f"❌ MSC gear file missing columns: {missing_msc_cols}")
            validation_passed = False
        else:
            logger.info(f"✅ MSC gear file structure valid: {len(msc_df)} records, columns: {list(msc_df.columns)}")
            
    except Exception as e:
        logger.error(f"❌ Could not validate MSC gear file: {e}")
        validation_passed = False
    
    # Check relationship file
    try:
        rel_df = pd.read_csv("/import/cleaned_gear_types_fao_msc_relationship.csv")
        required_rel_cols = ['msc_gear', 'fao_isscfg_alpha']
        
        missing_rel_cols = set(required_rel_cols) - set(rel_df.columns)
        if missing_rel_cols:
            logger.error(f"❌ Relationship file missing columns: {missing_rel_cols}")
            validation_passed = False
        else:
            logger.info(f"✅ Relationship file structure valid: {len(rel_df)} records, columns: {list(rel_df.columns)}")
            
    except Exception as e:
        logger.error(f"❌ Could not validate relationship file: {e}")
        validation_passed = False
    
    return validation_passed

def main():
    """Main function to run all enhanced cleaning operations."""
    logger.info("🚀 Starting ENHANCED MSC gear data cleaning (UUID Support)...")
    logger.info("🔧 Changes: Removed manual ID generation, database will use UUIDs")
    logger.info("📊 Source mapping will happen during SQL import phase")
    
    try:
        # Show the planned source mapping
        show_msc_source_mapping_plan()
        
        success_count = 0
        
        # Clean MSC gear types
        logger.info("\n🧼 Cleaning MSC gear types...")
        if clean_msc_gear_types():
            success_count += 1
        
        # Process MSC-FAO relationship
        logger.info("\n🧼 Processing MSC-FAO relationships...")
        if process_msc_fao_relationship():
            success_count += 1
        
        # Validate the results
        if success_count == 2 and validate_cleaned_data():
            logger.info("\n✅ All ENHANCED MSC gear data cleaning completed!")
            logger.info("🎯 Ready for UUID-based import with source tracking")
            logger.info("📊 All manual ID generation removed - database will handle UUIDs")
            logger.info("🔗 Source_id mapping will be handled in SQL import phase")
            logger.info("🎣 MSC gear table will connect to original_sources via MSC Fisheries")
            logger.info("🔄 Relationship table will use UUID foreign keys")
            return 0
        else:
            logger.error("\n❌ Enhanced MSC gear data cleaning validation failed")
            return 1
            
    except Exception as e:
        logger.error(f"❌ Enhanced MSC gear data cleaning failed: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())